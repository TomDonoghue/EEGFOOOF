{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Analysis - FOOOFed EEG Analysis: Task\n",
    "    \n",
    "Applying FOOOF to task based EEG data, and comparing between young and old groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- average power spectra vs. average FOOOFs\n",
    "    - there are 10 segments that don't return a value in the single channel version\n",
    "        - segments, with all-channel or canonical, have systematically different (lower) alpha power\n",
    "    - best performance (for both canonical & FOOOF) is from dropping those segments\n",
    "    - when doing single channel FOOOF, there is a benefit of other alpha features (CF & BW) \n",
    "\n",
    "Status:\n",
    "- FOOOF fits can help select data to analyze\n",
    "- Gives more features to use to predict behaviour, and can outperform canonical when these features are combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from os.path import join as pjoin\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.diagnostic import compare_cox, compare_j\n",
    "\n",
    "from fooof.synth.gen import gen_aperiodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom code for this analysis\n",
    "%autoreload 2\n",
    "from fio import *\n",
    "from plts import *\n",
    "from utils import *\n",
    "from data_mgmt import *\n",
    "from analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of young subjects:   17\n",
      "Number of  old  subjects:   14\n"
     ]
    }
   ],
   "source": [
    "# Set path to load results from\n",
    "res_path = '/Users/tom/Documents/Research/1-Projects/fooof/2-Data/Results/'\n",
    "\n",
    "# Set indices to separate groups\n",
    "from settings import YNG_INDS, OLD_INDS\n",
    "\n",
    "# Set which group of FOOOF results to load\n",
    "folder = 'FOOOF-SinCh'        # FOOOF fit on an average across power spectra \n",
    "#folder = 'FOOOF-AllCh'       # Average across FOOOF fits, from each channel\n",
    "\n",
    "# Wether to save out plots or not\n",
    "save_fig = False\n",
    "\n",
    "print('Number of young subjects:  ', len(YNG_INDS))\n",
    "print('Number of  old  subjects:  ', len(OLD_INDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data settings\n",
    "srate = 512\n",
    "tmin, tmax = -0.85, 1.1\n",
    "times = np.arange(tmin, tmax, 1/srate)\n",
    "seg_times = [(-0.85, -0.35), (0.1, 0.6), (0.5, 1.0)]\n",
    "n_subjs = 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check dropped trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubNum \t\t # Dropped Trials \t # Dropped Components\n"
     ]
    }
   ],
   "source": [
    "# Load dropped trials & components\n",
    "dropped_trials = np.load(pjoin(res_path, 'Group', 'dropped_trials.npy'))\n",
    "dropped_components = np.load(pjoin(res_path, 'Group', 'dropped_components.npy'))\n",
    "\n",
    "# Check dropped trials for each subject\n",
    "print('SubNum \\t\\t # Dropped Trials \\t # Dropped Components')\n",
    "for ind, trials, components in zip(range(n_subjs), dropped_trials, dropped_components):\n",
    "    temp_trials = trials[trials < 999.]\n",
    "    temp_comps = components[components < 999.]\n",
    "#    print(ind, '\\t\\t', len(temp_trials), '\\t\\t\\t', len(temp_comps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group FOOOFing - Trial Averaged Data\n",
    "\n",
    "Notes:\n",
    "- 3D data objects have the shape `[n_loads, n_subjs, n_times]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load behavioural data\n",
    "behav_dat = pd.read_csv(pjoin(res_path, 'Behav', 'neural_aging_data_behaviour.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "behav_dat['Age'] = behav_dat['Age'].astype('str')\n",
    "behav_dat['Load'] = behav_dat['Load'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average behaviour across loads\n",
    "avg_behav = behav_dat.groupby('SubjID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select age group of subjects\n",
    "#behav_dat = behav_dat[behav_dat['Age'] == '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHEATING\n",
    "#for ind in [28, 59, 90]:\n",
    "#    behav_dat.loc[ind, \"d'\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and extract FOOOF data\n",
    "all_offsets, all_exps = load_fooof_task_ap(res_path, 'Contra', folder)\n",
    "all_alphas_cf = load_fooof_task_pe(res_path, 'Contra', 0, folder)\n",
    "all_alphas =  load_fooof_task_pe(res_path, 'Contra', 1, folder)\n",
    "all_alphas_bw = load_fooof_task_pe(res_path, 'Contra', 2, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with row mean\n",
    "# import numpy.ma as ma\n",
    "# out = []\n",
    "# for mat in all_alphas:\n",
    "#     mat = mat.T\n",
    "#     out.append(np.where(np.isnan(mat), ma.array(mat, mask=np.isnan(mat)).mean(axis=0), mat).T)\n",
    "# all_alphas = np.stack(out)\n",
    "\n",
    "# Replace nan with global mean\n",
    "#all_alphas[np.isnan(all_alphas)] = np.nanmean(all_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load canonical alpha analysis\n",
    "canonical_group = np.load(pjoin(res_path, 'Group', 'canonical_group.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across analytic alpha measures to get canonical alpha measure\n",
    "seg_masks = []\n",
    "for seg in seg_times:\n",
    "    seg_masks.append(np.logical_and(times >= seg[0], times <= seg[1]))\n",
    "\n",
    "canalpha = np.zeros_like(all_alphas)\n",
    "for subi, subj_dat in enumerate(canonical_group):\n",
    "    for lodi in range(3):\n",
    "        for segi, mask in enumerate(seg_masks):\n",
    "            canalpha[lodi, subi, segi] = np.mean(subj_dat[lodi, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and extract FOOOF data\n",
    "# all_offsets = all_offsets[:, YNG_INDS, :]\n",
    "# all_exps = all_exps[:, YNG_INDS, :]\n",
    "# all_alphas_cf = all_alphas_cf[:, YNG_INDS, :]\n",
    "# all_alphas = all_alphas[:, YNG_INDS, :]\n",
    "# all_alphas_bw = all_alphas_bw[:, YNG_INDS, :]\n",
    "# canalpha = canalpha[:, YNG_INDS, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of missing FOOOFed alphas\n",
    "sum(sum(sum(np.isnan(all_alphas))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check where the NaN values are\n",
    "#nans = np.isnan(all_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop missing FOOOF values from other measures\n",
    "# canalpha[nans] = np.nan\n",
    "# all_exps[nans] = np.nan\n",
    "# all_offsets[nans] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST\n",
    "# all_alphas[nans] = np.nan\n",
    "# all_alphas_cf[nans] = np.nan\n",
    "# all_alphas_bw[nans] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTS - drop particular subjects\n",
    "# for drop_ind in [1, 8]:\n",
    "#     all_alphas[:, 1, :] = np.nan\n",
    "#     canalpha[:, 1, :] = np.nan\n",
    "#     all_exps[:, 1, :] = np.nan\n",
    "#     all_offsets[:, 1, :] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHEATING: DROP OUT SUBJECTS\n",
    "#behav_dat[behav_dat['SubjID'] == 8] = np.nan\n",
    "#behav_dat[behav_dat['SubjID'] == 1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_inds = np.where(np.isnan(all_alphas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(behav_dat['SubjID'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `[n_loads, n_subjs, n_times]`\n",
    "\n",
    "# df[(df>=0)&(df<=20)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(behav_dat.SubjID.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop behavioural data where the EEG data is NaN\n",
    "# all_inds = YNG_INDS + OLD_INDS\n",
    "# for load_ind, subj_ind, times_ind in zip(*nan_inds):\n",
    "#     if times_ind == 0 or times_ind == 2:\n",
    "#         index = behav_dat[(behav_dat['Load'] == str(load_ind + 1)) & \\\n",
    "#                           (behav_dat['SubjID'] == subj_ind + 1)].index\n",
    "#         print(load_ind+1, subj_ind, times_ind, '\\t', index)\n",
    "#         behav_dat.loc[index, \"d'\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'al_dif_yng' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-58f9c492e086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mal_dif_yng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mal_dif_old\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mqq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'al_dif_yng' is not defined"
     ]
    }
   ],
   "source": [
    "qq = np.where(np.isnan(np.concatenate([al_dif_yng, al_dif_old])))\n",
    "qq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_dat.query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'al_st_yng' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-5eea102ef288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mww\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mal_st_yng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mal_st_old\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'al_st_yng' is not defined"
     ]
    }
   ],
   "source": [
    "ww = np.vstack([al_st_yng, al_st_old])\n",
    "ww.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ww' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-a14ff78b5fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mww\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ww' is not defined"
     ]
    }
   ],
   "source": [
    "np.where(np.isnan(ww))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubjID         9\n",
       "Age            1\n",
       "Load           1\n",
       "CDA      -2.1048\n",
       "d'        4.2064\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behav_dat.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubjID         13\n",
       "Age             1\n",
       "Load            3\n",
       "CDA      -2.29152\n",
       "d'        3.93454\n",
       "Name: 74, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behav_dat.iloc[74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'al_dif_old' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-1828c55a6815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal_dif_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'al_dif_old' is not defined"
     ]
    }
   ],
   "source": [
    "np.where(np.isnan(al_dif_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'al_dif_old' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-3657a197b543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mal_dif_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'al_dif_old' is not defined"
     ]
    }
   ],
   "source": [
    "al_dif_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 1, 1, 2, 2, 2, 2, 2]),\n",
       " array([ 1,  8,  1,  1,  8,  1,  1,  3,  8, 29]),\n",
       " array([1, 0, 1, 2, 0, 1, 2, 1, 2, 2]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Load</th>\n",
       "      <th>CDA</th>\n",
       "      <th>d'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SubjID, Age, Load, CDA, d']\n",
       "Index: []"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behav_dat[np.isnan(behav_dat[\"d'\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'al_dif_old' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-45cfb820821b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal_dif_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal_dif_yng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'al_dif_old' is not defined"
     ]
    }
   ],
   "source": [
    "sum(np.isnan(al_dif_old)) + sum(np.isnan(al_dif_yng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.isnan(behav_dat[\"d'\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = np.isnan(all_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0.5009890129868549\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(all_alphas[nans]))\n",
    "print(np.mean(all_alphas[~nans]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "10.718838504875412\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(all_alphas_cf[nans]))\n",
    "print(np.mean(all_alphas_cf[~nans]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "3.5223403743838793\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(all_alphas_bw[nans]))\n",
    "print(np.mean(all_alphas_bw[~nans]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.3513236216584837e-07\n",
      "-8.196500058385066e-08\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(canalpha[nans]))\n",
    "print(np.mean(canalpha[~nans]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up th\n",
    "labels = ['offset', 'exponent', 'alpha_cf', 'alpha_pw', 'alpha_bw', 'canalpha']\n",
    "datas = [all_offsets, all_exps, all_alphas_cf, all_alphas, all_alphas_bw, canalpha]\n",
    "\n",
    "# Make a data dictionary - each with shape [n_conds, n_times]\n",
    "data_dict = {'YNG' : {}, 'OLD' : {}, 'ALL' : {}}\n",
    "diff_data_dict = deepcopy(data_dict)\n",
    "behav_dict = deepcopy(data_dict)\n",
    "i1, i2 = 2, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data & diff_data dicts\n",
    "for label, data in zip(labels, datas):\n",
    "    data_dict['YNG'][label], data_dict['OLD'][label] = reshape_dat(data)\n",
    "    data_dict['ALL'][label] = np.concatenate([data_dict['YNG'][label], data_dict['OLD'][label]])\n",
    "    \n",
    "    diff_data_dict['YNG'][label] = calc_diff(data_dict['YNG'][label], i1, i2)\n",
    "    diff_data_dict['OLD'][label] = calc_diff(data_dict['OLD'][label], i1, i2)\n",
    "    diff_data_dict['ALL'][label] = np.concatenate([diff_data_dict['YNG'][label], diff_data_dict['OLD'][label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the behavioural data dict\n",
    "for label in [\"d'\", \"Load\", 'CDA']:\n",
    "    behav_dict['ALL'][label] = behav_dat[label].values\n",
    "    behav_dict['YNG'][label] = behav_dat[behav_dat['Age'] == '1'][label].values\n",
    "    behav_dict['OLD'][label] = behav_dat[behav_dat['Age'] == '2'][label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ReOrg data - reshape 3D matrix, to 2D matrix with stacked trials\n",
    "# canal_st_yng, canal_st_old = reshape_dat(canalpha)\n",
    "\n",
    "# off_st_yng, off_st_old = reshape_dat(all_offsets)\n",
    "# exp_st_yng, exp_st_old = reshape_dat(all_exps)\n",
    "\n",
    "# al_st_yng, al_st_old = reshape_dat(all_alphas)\n",
    "# al_cf_st_yng, al_cf_st_old = reshape_dat(all_alphas_cf)\n",
    "# al_bw_st_yng, al_bw_st_old = reshape_dat(all_alphas_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate difference measures\n",
    "# i1, i2 = 2, 0\n",
    "\n",
    "# canal_dif_yng = calc_diff(canal_st_yng, i1, i2)\n",
    "# canal_dif_old = calc_diff(canal_st_old, i1, i2)\n",
    "\n",
    "# off_dif_yng = calc_diff(off_st_yng, i1, i2)\n",
    "# off_dif_old = calc_diff(off_st_old, i1, i2)\n",
    "\n",
    "# exp_dif_yng = calc_diff(exp_st_yng, i1, i2)\n",
    "# exp_dif_old = calc_diff(exp_st_old, i1, i2)\n",
    "\n",
    "# al_dif_yng = calc_diff(al_st_yng, i1, i2)\n",
    "# al_dif_old = calc_diff(al_st_old, i1, i2)\n",
    "\n",
    "# al_cf_dif_yng = calc_diff(al_cf_st_yng, i1, i2)\n",
    "# al_cf_dif_old = calc_diff(al_cf_st_old, i1, i2)\n",
    "\n",
    "# al_bw_dif_yng = calc_diff(al_bw_st_yng, i1, i2)\n",
    "# al_bw_dif_old = calc_diff(al_bw_st_old, i1, i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('CANALPHA - YNG: ', np.nanmean(canal_dif_yng))\n",
    "# print('CANALPHA - OLD: ', np.nanmean(canal_dif_old))\n",
    "\n",
    "# print('')\n",
    "# print('Alpha Power - YNG: ', np.nanmean(al_dif_yng))\n",
    "# print('Alpha Power - OLD: ', np.nanmean(al_dif_old))\n",
    "# print('')\n",
    "# print('Alpha CF - YNG: ', np.nanmean(al_cf_dif_yng))\n",
    "# print('Alpha CF - OLD: ', np.nanmean(al_cf_dif_old))\n",
    "# print('')\n",
    "# print('Alpha BW - YNG: ', np.nanmean(al_bw_dif_yng))\n",
    "# print('Alpha BW - OLD: ', np.nanmean(al_bw_dif_old))\n",
    "\n",
    "# print('')\n",
    "# print('Exp - YNG: ', np.nanmean(exp_dif_yng))\n",
    "# print('Exp - OLD: ', np.nanmean(exp_dif_old))\n",
    "# print('')\n",
    "# print('Off - YNG: ', np.nanmean(exp_dif_yng))\n",
    "# print('Off - OLD: ', np.nanmean(exp_dif_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t   YNG \t\t  OLD\n",
      "offset: \t -0.0717 \t-0.0888\n",
      "exponent: \t -0.0484 \t-0.0428\n",
      "alpha_cf: \t -0.1245 \t 0.6765\n",
      "alpha_pw: \t  0.0816 \t-0.0051\n",
      "alpha_bw: \t -0.2969 \t 0.2854\n",
      "canalpha: \t  0.0000 \t-0.0000\n"
     ]
    }
   ],
   "source": [
    "# Print out mean values per group\n",
    "print('\\t\\t   YNG \\t\\t  OLD')\n",
    "for label in labels:\n",
    "    print_stat(label,\n",
    "               np.nanmean(diff_data_dict['YNG'][label]),\n",
    "               np.nanmean(diff_data_dict['OLD'][label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t   YNG \t\t  OLD\n",
      "offset: \t  0.6957 \t 0.4884\n",
      "exponent: \t -0.2416 \t 0.8096\n",
      "alpha_cf: \t -3.8230 \t 0.0003\n",
      "alpha_pw: \t  2.7494 \t 0.0073\n",
      "alpha_bw: \t -3.7894 \t 0.0003\n",
      "canalpha: \t  2.2754 \t 0.0252\n"
     ]
    }
   ],
   "source": [
    "# Print out tests for group differences\n",
    "print('\\t\\t   YNG \\t\\t  OLD')\n",
    "for label in labels:\n",
    "    print_stat(label, *nan_ttest(diff_data_dict['YNG'][label], diff_data_dict['OLD'][label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_stat('CanAl', *nan_ttest(canal_dif_yng, canal_dif_old))\n",
    "\n",
    "# print('')\n",
    "# print_stat('Al-CF', *nan_ttest(al_cf_dif_yng, al_cf_dif_old))\n",
    "# print_stat('Al-PW', *nan_ttest(al_dif_yng, al_dif_old))\n",
    "# print_stat('Al-BW', *nan_ttest(al_bw_dif_yng, al_bw_dif_old))\n",
    "\n",
    "# print('')\n",
    "# print_stat('Exp', *nan_ttest(exp_dif_yng, exp_dif_old))\n",
    "# print_stat('Off', *nan_ttest(off_dif_yng, off_dif_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t   YNG \t\t  OLD\n",
      "offset: \t  0.1978 \t 0.0474\n",
      "exponent: \t  0.3171 \t-0.1065\n",
      "alpha_cf: \t  0.1978 \t 0.0086\n",
      "alpha_pw: \t -0.1362 \t 0.3408\n",
      "alpha_bw: \t  0.1042 \t 0.0289\n",
      "canalpha: \t -0.1787 \t 0.2544\n"
     ]
    }
   ],
   "source": [
    "# Print out tests for group differences\n",
    "print('\\t\\t   YNG \\t\\t  OLD')\n",
    "for label in labels:\n",
    "    print_stat(label,\n",
    "    nan_corr(diff_data_dict['YNG'][label], behav_dict['YNG'][\"d'\"])[0],\n",
    "    nan_corr(diff_data_dict['OLD'][label], behav_dict['OLD'][\"d'\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check correlations of difference measures with behaviour\n",
    "# print_stat('Sl-Yng', *nan_corr(exp_dif_yng, behav_dat[behav_dat.Age == '1'][\"d'\"]))\n",
    "# print_stat('Sl-Old', *nan_corr(exp_dif_old, behav_dat[behav_dat.Age == '2'][\"d'\"]))\n",
    "# print('')\n",
    "# print_stat('CanAl-Yng', *nan_corr(canal_dif_yng, behav_dat[behav_dat.Age == '1'][\"d'\"]))\n",
    "# print_stat('CanAl-Old', *nan_corr(canal_dif_old, behav_dat[behav_dat.Age == '2'][\"d'\"]))\n",
    "# print('')\n",
    "# print_stat('Al-Yng', *nan_corr(al_dif_yng, behav_dat[behav_dat.Age == '1'][\"d'\"]))\n",
    "# print_stat('Al-Old', *nan_corr(al_dif_old, behav_dat[behav_dat.Age == '2'][\"d'\"]))\n",
    "# print('')\n",
    "# print_stat('Al-CF-Yng', *nan_corr(al_cf_dif_yng, behav_dat[behav_dat.Age == '1'][\"d'\"]))\n",
    "# print_stat('Al-CF-Old', *nan_corr(al_cf_dif_old, behav_dat[behav_dat.Age == '2'][\"d'\"]))\n",
    "# print('')\n",
    "# print_stat('Al-BW-Yng', *nan_corr(al_bw_dif_yng, behav_dat[behav_dat.Age == '1'][\"d'\"]))\n",
    "# print_stat('Al-BW-Old', *nan_corr(al_bw_dif_old, behav_dat[behav_dat.Age == '2'][\"d'\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference Measures\n",
    "\n",
    "Predict behaviour output from evoked responses of alpha and aperiodic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SETTINGS\n",
    "group = 'ALL' # 'ALL', 'YNG', 'OLD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model (Predict from load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  behav   R-squared:                       0.130\n",
      "Model:                            OLS   Adj. R-squared:                  0.111\n",
      "Method:                 Least Squares   F-statistic:                     6.736\n",
      "Date:                Wed, 06 Mar 2019   Prob (F-statistic):            0.00188\n",
      "Time:                        16:56:33   Log-Likelihood:                -123.85\n",
      "No. Observations:                  93   AIC:                             253.7\n",
      "Df Residuals:                      90   BIC:                             261.3\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.8056      0.167     22.743      0.000       3.473       4.138\n",
      "load[T.2]     -0.2406      0.237     -1.017      0.312      -0.711       0.230\n",
      "load[T.3]     -0.8431      0.237     -3.563      0.001      -1.313      -0.373\n",
      "==============================================================================\n",
      "Omnibus:                        1.414   Durbin-Watson:                   1.811\n",
      "Prob(Omnibus):                  0.493   Jarque-Bera (JB):                1.403\n",
      "Skew:                          -0.205   Prob(JB):                        0.496\n",
      "Kurtosis:                       2.560   Cond. No.                         3.73\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_def = 'behav ~ load'\n",
    "data_def = {'behav' : behav_dict[group][\"d'\"],\n",
    "            'load' : behav_dict[group]['Load']}\n",
    "base_model = run_model(model_def, data_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  behav   R-squared:                       0.130\n",
      "Model:                            OLS   Adj. R-squared:                  0.101\n",
      "Method:                 Least Squares   F-statistic:                     4.442\n",
      "Date:                Wed, 06 Mar 2019   Prob (F-statistic):            0.00589\n",
      "Time:                        16:56:33   Log-Likelihood:                -123.85\n",
      "No. Observations:                  93   AIC:                             255.7\n",
      "Df Residuals:                      89   BIC:                             265.8\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.8009      0.189     20.129      0.000       3.426       4.176\n",
      "load[T.2]     -0.2431      0.242     -1.003      0.319      -0.725       0.238\n",
      "load[T.3]     -0.8470      0.248     -3.411      0.001      -1.340      -0.354\n",
      "cda           -0.0054      0.098     -0.055      0.956      -0.201       0.190\n",
      "==============================================================================\n",
      "Omnibus:                        1.418   Durbin-Watson:                   1.814\n",
      "Prob(Omnibus):                  0.492   Jarque-Bera (JB):                1.399\n",
      "Skew:                          -0.202   Prob(JB):                        0.497\n",
      "Kurtosis:                       2.555   Cond. No.                         6.36\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_def = 'behav ~ load + cda'\n",
    "data_def = {'behav' : behav_dict[group][\"d'\"],\n",
    "            'load' : behav_dict[group]['Load'],\n",
    "            'cda' : behav_dict[group]['CDA']}\n",
    "cda_model = run_model(model_def, data_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canonical Alpha Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  behav   R-squared:                       0.132\n",
      "Model:                            OLS   Adj. R-squared:                  0.103\n",
      "Method:                 Least Squares   F-statistic:                     4.517\n",
      "Date:                Wed, 06 Mar 2019   Prob (F-statistic):            0.00538\n",
      "Time:                        16:56:34   Log-Likelihood:                -123.75\n",
      "No. Observations:                  93   AIC:                             255.5\n",
      "Df Residuals:                      89   BIC:                             265.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.7960      0.169     22.398      0.000       3.459       4.133\n",
      "load[T.2]     -0.2309      0.239     -0.967      0.336      -0.705       0.243\n",
      "load[T.3]     -0.8246      0.241     -3.417      0.001      -1.304      -0.345\n",
      "al_dif      5.677e+04   1.28e+05      0.445      0.657   -1.97e+05     3.1e+05\n",
      "==============================================================================\n",
      "Omnibus:                        1.542   Durbin-Watson:                   1.823\n",
      "Prob(Omnibus):                  0.463   Jarque-Bera (JB):                1.463\n",
      "Skew:                          -0.196   Prob(JB):                        0.481\n",
      "Kurtosis:                       2.527   Cond. No.                     1.47e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.38e-11. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "model_def = 'behav ~ load + al_dif'\n",
    "data_def = {'behav' : behav_dict[group][\"d'\"],\n",
    "            'load' : behav_dict[group]['Load'],\n",
    "            'al_dif' : diff_data_dict['ALL']['canalpha']}\n",
    "canalpha_model = run_model(model_def, data_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOOOF Alpha Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  behav   R-squared:                       0.159\n",
      "Model:                            OLS   Adj. R-squared:                  0.129\n",
      "Method:                 Least Squares   F-statistic:                     5.228\n",
      "Date:                Wed, 06 Mar 2019   Prob (F-statistic):            0.00235\n",
      "Time:                        16:56:34   Log-Likelihood:                -115.59\n",
      "No. Observations:                  87   AIC:                             239.2\n",
      "Df Residuals:                      83   BIC:                             249.1\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.7603      0.178     21.090      0.000       3.406       4.115\n",
      "load[T.2]     -0.2466      0.244     -1.012      0.314      -0.731       0.238\n",
      "load[T.3]     -0.8927      0.253     -3.525      0.001      -1.396      -0.389\n",
      "al_dif         0.5222      0.688      0.759      0.450      -0.845       1.890\n",
      "==============================================================================\n",
      "Omnibus:                        1.824   Durbin-Watson:                   1.869\n",
      "Prob(Omnibus):                  0.402   Jarque-Bera (JB):                1.518\n",
      "Skew:                          -0.164   Prob(JB):                        0.468\n",
      "Kurtosis:                       2.443   Cond. No.                         7.69\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_def = 'behav ~ load + al_dif'\n",
    "data_def = {'behav' : behav_dict[group][\"d'\"],\n",
    "            'load' : behav_dict[group]['Load'],\n",
    "            'al_dif' : diff_data_dict[group]['alpha_pw']}\n",
    "f_alpha_model = run_model(model_def, data_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOOOF Alpha+ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  behav   R-squared:                       0.214\n",
      "Model:                            OLS   Adj. R-squared:                  0.165\n",
      "Method:                 Least Squares   F-statistic:                     4.400\n",
      "Date:                Wed, 06 Mar 2019   Prob (F-statistic):            0.00136\n",
      "Time:                        16:56:35   Log-Likelihood:                -112.67\n",
      "No. Observations:                  87   AIC:                             237.3\n",
      "Df Residuals:                      81   BIC:                             252.1\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.6444      0.181     20.103      0.000       3.284       4.005\n",
      "load[T.2]     -0.2393      0.242     -0.990      0.325      -0.720       0.241\n",
      "load[T.3]     -0.8354      0.256     -3.270      0.002      -1.344      -0.327\n",
      "al_cf_dif      0.2861      0.176      1.621      0.109      -0.065       0.637\n",
      "al_dif         0.6748      0.682      0.989      0.326      -0.683       2.032\n",
      "al_bw_dif     -0.5487      0.237     -2.315      0.023      -1.020      -0.077\n",
      "==============================================================================\n",
      "Omnibus:                        0.881   Durbin-Watson:                   1.890\n",
      "Prob(Omnibus):                  0.644   Jarque-Bera (JB):                0.927\n",
      "Skew:                          -0.229   Prob(JB):                        0.629\n",
      "Kurtosis:                       2.787   Cond. No.                         9.06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_def = 'behav ~ load + al_cf_dif + al_dif + al_bw_dif'\n",
    "data_def = {'behav' : behav_dict[group][\"d'\"],\n",
    "            'load' : behav_dict[group]['Load'],\n",
    "            'al_cf_dif' : diff_data_dict[group]['alpha_cf'],\n",
    "            'al_dif' : diff_data_dict[group]['alpha_pw'],\n",
    "            'al_bw_dif' : diff_data_dict[group]['alpha_bw']}\n",
    "f_alpha_plus_model = run_model(model_def, data_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting from FOOOF: Aperiodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  behav   R-squared:                       0.141\n",
      "Model:                            OLS   Adj. R-squared:                  0.102\n",
      "Method:                 Least Squares   F-statistic:                     3.611\n",
      "Date:                Wed, 06 Mar 2019   Prob (F-statistic):            0.00898\n",
      "Time:                        16:56:35   Log-Likelihood:                -123.27\n",
      "No. Observations:                  93   AIC:                             256.5\n",
      "Df Residuals:                      88   BIC:                             269.2\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.8603      0.183     21.133      0.000       3.497       4.223\n",
      "load[T.2]     -0.2313      0.238     -0.971      0.334      -0.705       0.242\n",
      "load[T.3]     -0.8292      0.241     -3.443      0.001      -1.308      -0.351\n",
      "exp_dif        0.3014      2.219      0.136      0.892      -4.109       4.712\n",
      "off_dif        0.6122      2.073      0.295      0.768      -3.507       4.732\n",
      "==============================================================================\n",
      "Omnibus:                        1.278   Durbin-Watson:                   1.791\n",
      "Prob(Omnibus):                  0.528   Jarque-Bera (JB):                1.339\n",
      "Skew:                          -0.224   Prob(JB):                        0.512\n",
      "Kurtosis:                       2.618   Cond. No.                         34.3\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_def = 'behav ~ load + exp_dif + off_dif'\n",
    "data_def = {'behav' : behav_dict[group][\"d'\"],\n",
    "            'load' : behav_dict[group]['Load'],\n",
    "            'off_dif' : diff_data_dict[group]['offset'],\n",
    "            'exp_dif' : diff_data_dict[group]['exponent']}\n",
    "f_alpha_plus_model = run_model(model_def, data_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predicting from FOOOF model with Alpha & Aperiodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  behav   R-squared:                       0.164\n",
      "Model:                            OLS   Adj. R-squared:                  0.112\n",
      "Method:                 Least Squares   F-statistic:                     3.170\n",
      "Date:                Wed, 06 Mar 2019   Prob (F-statistic):             0.0115\n",
      "Time:                        16:56:36   Log-Likelihood:                -115.35\n",
      "No. Observations:                  87   AIC:                             242.7\n",
      "Df Residuals:                      81   BIC:                             257.5\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.7951      0.201     18.906      0.000       3.396       4.195\n",
      "load[T.2]     -0.2344      0.248     -0.945      0.347      -0.728       0.259\n",
      "load[T.3]     -0.8620      0.260     -3.318      0.001      -1.379      -0.345\n",
      "al_dif         0.5906      0.766      0.771      0.443      -0.933       2.115\n",
      "exp_dif        0.0969      2.630      0.037      0.971      -5.135       5.329\n",
      "off_dif        0.5304      2.330      0.228      0.821      -4.106       5.167\n",
      "==============================================================================\n",
      "Omnibus:                        1.653   Durbin-Watson:                   1.879\n",
      "Prob(Omnibus):                  0.438   Jarque-Bera (JB):                1.461\n",
      "Skew:                          -0.177   Prob(JB):                        0.482\n",
      "Kurtosis:                       2.474   Cond. No.                         38.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_def = 'behav ~ load + al_dif + exp_dif + off_dif'\n",
    "data_def = {'behav' : behav_dict[group][\"d'\"],\n",
    "            'load' : behav_dict[group]['Load'],\n",
    "            'al_dif' : diff_data_dict[group]['alpha_pw'],\n",
    "            'off_dif' : diff_data_dict[group]['offset'],\n",
    "            'exp_dif' : diff_data_dict[group]['exponent']}\n",
    "f_alpha_plus_model = run_model(model_def, data_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOMETHING ELSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadi = 2\n",
    "# time_exps = all_exps[loadi, inds, :].mean(0)\n",
    "# time_offs = all_offsets[loadi, inds, :].mean(0)\n",
    "\n",
    "# time_al_cf = all_alphas_cf[loadi, inds, :].mean(0)\n",
    "# time_al_pw = all_alphas[loadi, inds, :].mean(0)\n",
    "# time_al_bw = all_alphas_bw[loadi, inds, :].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(al_dif_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = YNG_INDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_exps = all_exps[:, inds, :].mean(0).mean(0)\n",
    "time_offs = all_offsets[:, inds, :].mean(0).mean(0)\n",
    "\n",
    "time_al_cf = all_alphas_cf[:, inds, :].mean(0).mean(0)\n",
    "time_al_pw = all_alphas[:, inds, :].mean(0).mean(0)\n",
    "time_al_bw = all_alphas_bw[:, inds, :].mean(0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_al_pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, base_spectrum = gen_power_spectrum([3, 30],\n",
    "                                       [time_offs[0], time_exps[0]],\n",
    "                                       [time_al_cf[0], time_al_pw[0], time_al_bw[0]/2], nlv=0)\n",
    "fs, task_spectrum = gen_power_spectrum([3, 30],\n",
    "                                       [time_offs[2], time_exps[2]],\n",
    "                                       [time_al_cf[2], time_al_pw[2], time_al_bw[2]/2], nlv=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_spectra(fs, [base_spectrum, task_spectrum], True, True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fooof.synth.gen import gen_power_spectrum\n",
    "from fooof.plts import plot_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_power_spectrum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(al_dif_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparisons\n",
    "\n",
    "Explicitly test for differences between different model fits. \n",
    "\n",
    "#### Comparing Nested Models\n",
    "\n",
    "Statsmodels offers three tests for nested models: f test, lagrange multiplier, likelihood ratio\n",
    "\n",
    "Note that these three can be called from a results object, as `compare_x_test` with `f`, `lm` and `lr` as `x`. \n",
    "\n",
    "F-test can also be run with `anova_lm`. \n",
    "\n",
    "#### Comparing Non-Nested Models\n",
    "\n",
    "Statmodels offers two tests for non-nested model: cox test & j test\n",
    "\n",
    "They are better described in the R implementations:\n",
    "\n",
    "- cox_test: http://math.furman.edu/~dcs/courses/math47/R/library/lmtest/html/coxtest.html\n",
    "- j_test: http://math.furman.edu/~dcs/courses/math47/R/library/lmtest/html/jtest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare nested models: alpha models vs base models\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print('Canonical alpha vs. Base Model')\n",
    "    print(anova_lm(mod_base, mod_alpha_can))\n",
    "    print('\\n')\n",
    "    print('FOOOFed alpha vs. Base Model')\n",
    "    print(anova_lm(mod_base, mod_alpha_foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different alpha models\n",
    "print('Canonical alpha vs. FOOOFed Alpha')\n",
    "print_stat('Alpha-Model Compare', *compare_cox.run(mod_alpha_can, mod_alpha_foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different alpha models\n",
    "print('Canonical alpha vs. FOOOFed Alpha')\n",
    "print_stat('Alpha-Model Compare', *compare_cox.run(mod_alpha_can, mod_alpha_foo_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare nested model: aperiodic exponent\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print('FOOOF aperiodic vs. Base Model')\n",
    "    print(anova_lm(mod_base, mod_exponent_foo))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the full FOOOF model to the one with canonical alpha\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print('FOOOF Full vs. Canonical Alpha')\n",
    "    print(anova_lm(mod_alpha_can, mod_all_foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare FOOOF model with exponent to restricted model with just alpha (from FOOOF)\n",
    "lm_val, p_val, df_diff = mod_all_foo.compare_f_test(mod_alpha_foo)\n",
    "print_stat('Model comp', lm_val, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "Check the correlational structure between canonical and FOOOF features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the power @ alpha frequency given the aperiodic component, from the FOOOF fits\n",
    "ap_alpha = []\n",
    "for cf, off, exp in zip(all_alphas_cf.flatten(), all_offsets.flatten(), all_exps.flatten()):\n",
    "    ap_alpha.append(gen_aperiodic(np.array([10]), [off, exp])[0])\n",
    "ap_alpha = np.array(ap_alpha)\n",
    "\n",
    "# Calculate the total power at 10 Hz (or about) from the \n",
    "foo_total = ap_alpha + all_alphas.flatten()\n",
    "\n",
    "# Find NaN locations\n",
    "nan_inds = np.isnan(ap_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between canonical and FOOOF alpha\n",
    "print_stat('CanalvsFAlpha', *pearsonr(np.array(canalpha.flatten())[~nan_inds], np.array(all_alphas.flatten())[~nan_inds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between canonical alpha and aperiodic component @ 10 Hz\n",
    "print_stat('Canalvs10HzAP', *pearsonr(np.array(canalpha.flatten())[~nan_inds], np.array(ap_alpha)[~nan_inds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between the canonical alpha and the FOOOF model total @ 10 Hz\n",
    "print_stat('CanalvsTotalFOOOF',*pearsonr(np.array(canalpha.flatten())[~nan_inds], np.array(foo_total.flatten())[~nan_inds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation between exponent & d', and alpha & d' - for a specific load and time point\n",
    "\n",
    "# Set which load and time point to use\n",
    "l_ind = 0\n",
    "t_ind = 0\n",
    "\n",
    "print_stat(\"Sl-Lo-d'\", *pearsonr(all_exps[l_ind, :, t_ind],\n",
    "                                 behav_dat[behav_dat.Load == str(l_ind + 1)][\"d'\"]))\n",
    "print_stat(\"Al-Lo-d'\", *pearsonr(all_alphas[l_ind, :, t_ind],\n",
    "                                 behav_dat[behav_dat.Load == str(l_ind + 1)][\"d'\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ind = 2\n",
    "\n",
    "print_stat(\"Sl-d'\", *pearsonr(all_exps[:, :, t_ind].flatten(), behav_dat[\"d'\"].values))\n",
    "print_stat(\"Al-d'\", *pearsonr(all_alphas[:, :, t_ind].flatten(), behav_dat[\"d'\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average d' with average measures\n",
    "t_ind = 2\n",
    "print_stat('XX', *pearsonr(avg_behav[\"d'\"], np.mean(all_exps[:, :, t_ind], 0)))\n",
    "print_stat('XX', *pearsonr(avg_behav[\"d'\"], np.mean(all_alphas[:, :, t_ind], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average d' with average measures: diff measures\n",
    "t_ind = 2\n",
    "print_stat('XX', *pearsonr(avg_behav[\"d'\"], np.mean(all_exps[:, :, 2] - all_exps[:, :, 0], 0)))\n",
    "print_stat('XX', *pearsonr(avg_behav[\"d'\"], np.mean(all_alphas[:, :, 2] - all_alphas[:, :, 0], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2\n",
    "\n",
    "print_stat('Yng-Sl', *pearsonr(exp_st_yng[:, ind], behav_dat[behav_dat.Age == '1'][\"d'\"]))\n",
    "print_stat('Old-Sl', *pearsonr(exp_st_old[:, ind], behav_dat[behav_dat.Age == '2'][\"d'\"]))\n",
    "\n",
    "print('')\n",
    "\n",
    "print_stat('Yng-Al', *pearsonr(al_st_yng[:, ind], behav_dat[behav_dat.Age == '1'][\"d'\"]))\n",
    "print_stat('Old-Al', *pearsonr(al_st_old[:, ind], behav_dat[behav_dat.Age == '2'][\"d'\"]))\n",
    "\n",
    "print('')\n",
    "\n",
    "print_stat('Yng-CanAl', *pearsonr(canal_st_yng[:, ind], behav_dat[behav_dat.Age == '1'][\"d'\"]))\n",
    "print_stat('Old-CanAl', *pearsonr(canal_st_old[:, ind], behav_dat[behav_dat.Age == '2'][\"d'\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across loads\n",
    "sl_resps = np.diff(np.mean(all_exps, 0))\n",
    "al_resps = np.diff(np.mean(all_alphas, 0))\n",
    "\n",
    "# # Take specific load\n",
    "# load_ind = 2\n",
    "# sl_resps = all_exps[load_ind, :, :]\n",
    "# al_resps = all_alphas[load_ind, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations between reactivity measures\n",
    "print_stat('SLR & ALR - 1', *pearsonr(sl_resps[:, 0], al_resps[:, 0]))\n",
    "print_stat('SLR & ALR - 2', *pearsonr(sl_resps[:, 1], al_resps[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = 0\n",
    "# edat = sl_resps\n",
    "\n",
    "# print_stat('\\tALL', *pearsonr(avg_behav[\"d'\"], al_resps[:, 0]))\n",
    "# print_stat('\\tYNG', *pearsonr(avg_behav[avg_behav['Age'] == '1'][\"d'\"], edat[YNG_INDS, ind]))\n",
    "# print_stat('\\tOLD', *pearsonr(avg_behav[avg_behav['Age'] == '2'][\"d'\"], edat[OLD_INDS, ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edat = sl_resps\n",
    "\n",
    "# print_stat('\\tALL', *pearsonr(avg_behav[\"d'\"], al_resps[:, 0]))\n",
    "# print_stat('\\tYNG', *pearsonr(avg_behav[avg_behav['Age'] == 1][\"d'\"], np.mean(edat[YNG_INDS], 1)))\n",
    "# print_stat('\\tOLD', *pearsonr(avg_behav[avg_behav['Age'] == 2][\"d'\"], np.mean(edat[OLD_INDS], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pearsonr(avg_behav[\"CDA\"], al_resps[:, 0]))\n",
    "print(pearsonr(avg_behav[\"CDA\"], sl_resps[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pearsonr(exp_dif_yng, al_dif_yng))\n",
    "print(pearsonr(exp_dif_old, al_dif_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous Crap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the dataframe\n",
    "\n",
    "# t_ind = 2\n",
    "# l_ind = 0 \n",
    "\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# df['behav'] = behav_dat[behav_dat['Load'] == l_ind+1][\"d'\"].values\n",
    "# df['age'] = behav_dat[behav_dat['Load'] == l_ind+1][\"Age\"].values\n",
    "\n",
    "# df['exp_dif'] = np.concatenate([exp_dif_yng, exp_dif_old])\n",
    "# df['al_dif'] = np.concatenate([al_dif_yng, al_dif_old])\n",
    "\n",
    "# # \n",
    "# outcome, predictors = patsy.dmatrices(\"behav ~ exp_dif + al_dif + age\", df)\n",
    "# #outcome, predictors = patsy.dmatrices(\"behav ~ age * exp_dif\", df)\n",
    "# mod = sm.OLS(outcome, predictors)\n",
    "# res = mod.fit()\n",
    "\n",
    "# # Check out the results\n",
    "# print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "al_ = np.mean(all_exps[:, YNG_INDS, :], 0)\n",
    "\n",
    "exp_st_yng = np.vstack([all_exps[0, YNG_INDS, :], all_exps[1, YNG_INDS, :], all_exps[2, YNG_INDS, :]])\n",
    "exp_st_old = np.vstack([all_exps[0, OLD_INDS, :], all_exps[1, OLD_INDS, :], all_exps[2, OLD_INDS, :]])\n",
    "\n",
    "#\n",
    "al_st_yng = np.vstack([all_alphas[0, YNG_INDS, :], all_alphas[1, YNG_INDS, :], all_alphas[2, YNG_INDS, :]])\n",
    "al_st_old = np.vstack([all_alphas[0, OLD_INDS, :], all_alphas[1, OLD_INDS, :], all_alphas[2, OLD_INDS, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the change in behavioural scores between highes & lowest loads\n",
    "delta_behavs = []\n",
    "temp_df = behav_dat[behav_dat.Age == 1]\n",
    "for subj_id in set(temp_df.SubjID.values):\n",
    "    temp = behav_dat[behav_dat.SubjID == subj_id]\n",
    "    delta_behavs.append(temp[temp.Load == 3][\"d'\"].values[0] - temp[temp.Load == 1][\"d'\"].values[0])\n",
    "delta_behavs = np.array(delta_behavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#behav_dat.Age == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the change in physiological scores between highes & lowest loads\n",
    "temp_dat = all_exps\n",
    "temp = temp_dat[2, :, :] - temp_dat[0, :, :]\n",
    "temp[np.isnan(temp)] = 0\n",
    "delta_phys = temp[:, 2] - temp[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('ALL:', pearsonr(delta_behavs, delta_phys[OLD_INDS]))\n",
    "#plt.scatter(delta_behavs, delta_phys[OLD_INDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('ALL:', pearsonr(delta_behavs, delta_phys[YNG_INDS]))\n",
    "#plt.scatter(delta_behavs, delta_phys[YNG_INDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(delta_behavs[OLD_INDS], delta_phys[OLD_INDS], label='OLD')\n",
    "# print('OLD:', pearsonr(delta_behavs[OLD_INDS], delta_phys[OLD_INDS]))\n",
    "# plt.scatter(delta_behavs[YNG_INDS], delta_phys[YNG_INDS], label='YNG')\n",
    "# print('YNG:', pearsonr(delta_behavs[YNG_INDS], delta_phys[YNG_INDS]))\n",
    "# plt.legend()\n",
    "# plt.xlabel('Delta Behav');\n",
    "# plt.ylabel('Delta Physiology');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur_dat = canalpha\n",
    "#cur_dat = all_exps\n",
    "cur_dat = all_alphas\n",
    "\n",
    "# Get phys-responsiveness, as late minus pre\n",
    "temp = cur_dat[:, :, 2] - cur_dat[:, :, 1]\n",
    "# Or - just take late\n",
    "#temp = cur_dat[:, :, 2]\n",
    "\n",
    "# Replace any nans as zeros\n",
    "temp[np.isnan(temp)] = 0\n",
    "\n",
    "# Get delta physiology as high load minus low load\n",
    "delta_phys = temp[2, :] - temp[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('ALL:', pearsonr(delta_behavs, delta_phys))\n",
    "# print('OLD:', pearsonr(delta_behavs[OLD_INDS], delta_phys[OLD_INDS]))\n",
    "# print('YNG:', pearsonr(delta_behavs[YNG_INDS], delta_phys[YNG_INDS]))\n",
    "\n",
    "# plt.scatter(delta_behavs[OLD_INDS], delta_phys[OLD_INDS], label='OLD')\n",
    "# plt.scatter(delta_behavs[YNG_INDS], delta_phys[YNG_INDS], label='YNG')\n",
    "\n",
    "# #plt.ylim([-0.0000005, 0.0000005])\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('Delta Behav');\n",
    "# plt.ylabel('Delta Physiology');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "for si, dd in zip(range(31), sum(np.isnan(all_alphas), 0).sum(1)):\n",
    "    print(si, '\\t', dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict canonalpha from FOOOF alpha + chi\n",
    "\n",
    "1) Canonical Alpha vs. FOOOF alpha\n",
    "\n",
    "2) Canonical Alpha vs. Chi\n",
    "\n",
    "3) Canonical Alpha cs. FOOOF alpha + chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_scaled = preprocessing.scale(canalpha.flatten())\n",
    "alf_scaled = preprocessing.scale(all_alphas.flatten())\n",
    "exp_scaled = preprocessing.scale(all_exps.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(alf_scaled, can_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(exp_scaled, can_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(exp_scaled, alf_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(canalpha.flatten(), all_alphas.flatten())\n",
    "plt.xlim([canalpha.flatten().min(), canalpha.flatten().max()]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alf_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exp_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['exp'] = np.concatenate([exp_dif_yng, exp_dif_old])\n",
    "df['fal'] = np.concatenate([al_dif_yng, al_dif_old])\n",
    "df['canal'] = np.concatenate([canal_dif_yng, canal_dif_old])\n",
    "#df['exp'] = all_exps[:, :, 1].flatten()\n",
    "#df['fal'] = all_alphas[:, :, 1].flatten()\n",
    "#df['canal'] = canalpha[:, :, 1].flatten()\n",
    "\n",
    "outcome, predictors = patsy.dmatrices(\"canal ~ fal * exp\", df)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "\n",
    "# Check out the results\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original values and predictions of alpha\n",
    "canal_vals = df['canal'].values[~np.isnan(df['canal'])]\n",
    "canalpha_predictions = res.predict(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between measured values and predictions\n",
    "plt.scatter(canalpha_predictions, canal_vals)\n",
    "plt.xlim([outcome.min(), outcome.max()]);\n",
    "plt.ylim([outcome.min(), outcome.max()]);\n",
    "nan_corr(canal_vals, canalpha_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat('YNG:', *nan_corr(al_dif_yng, al_cf_dif_yng))\n",
    "print_stat('OLD:', *nan_corr(al_dif_old, al_cf_dif_old))\n",
    "print_stat('ALL:', *nan_corr(np.concatenate([al_dif_yng, al_dif_old]),\n",
    "                             np.concatenate([al_cf_dif_yng, al_cf_dif_old])))\n",
    "\n",
    "\n",
    "plt.scatter(np.concatenate([al_dif_yng, al_dif_old]), np.concatenate([al_cf_dif_yng, al_cf_dif_old]))\n",
    "nan_corr(np.concatenate([al_dif_yng, al_dif_old]), np.concatenate([al_cf_dif_yng, al_cf_dif_old]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
